{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/home/stasysp/Envs/Datasets/MOT16/',\n",
      " 'deepmatch': '/home/stasysp/Envs/shad/project/cabbage/deepmatching_bin/deepmatching_1.2.2_c++/deepmatching-static',\n",
      " 'graph_solver': '/home/stasysp/Envs/shad/project/cabbage/build/sample'}\n",
      "Found model /home/stasysp/Envs/Datasets/MOT16/reid_models/stacknet64x64_84_BOTH.h5! :)\n",
      "Dt (3105, 6)\n",
      "[1.0000e+00 1.3591e+03 4.1327e+02 1.2026e+02 3.6277e+02 2.3092e+00] [ 6.3000e+01  1.5265e+03  4.2372e+02  4.4948e+01  1.3684e+02 -2.0395e-01]\n",
      "62\n",
      "prediction 0.0007192656\n",
      "handled 0 out of 3105\n",
      "handled 1 out of 3105\n",
      "handled 2 out of 3105\n",
      "handled 3 out of 3105\n",
      "handled 4 out of 3105\n",
      "handled 5 out of 3105\n",
      "handled 6 out of 3105\n",
      "handled 7 out of 3105\n",
      "handled 8 out of 3105\n",
      "handled 9 out of 3105\n",
      "handled 10 out of 3105\n",
      "handled 11 out of 3105\n",
      "handled 12 out of 3105\n",
      "handled 13 out of 3105\n",
      "handled 14 out of 3105\n",
      "handled 15 out of 3105\n",
      "handled 16 out of 3105\n",
      "handled 17 out of 3105\n",
      "handled 18 out of 3105\n",
      "handled 19 out of 3105\n",
      "handled 20 out of 3105\n",
      "handled 21 out of 3105\n",
      "handled 22 out of 3105\n",
      "handled 23 out of 3105\n",
      "handled 24 out of 3105\n",
      "handled 25 out of 3105\n",
      "handled 26 out of 3105\n",
      "handled 27 out of 3105\n",
      "handled 28 out of 3105\n",
      "handled 29 out of 3105\n",
      "handled 30 out of 3105\n",
      "handled 31 out of 3105\n",
      "handled 32 out of 3105\n",
      "handled 33 out of 3105\n",
      "handled 34 out of 3105\n",
      "handled 35 out of 3105\n",
      "handled 36 out of 3105\n",
      "handled 37 out of 3105\n",
      "handled 38 out of 3105\n",
      "handled 39 out of 3105\n",
      "handled 40 out of 3105\n",
      "handled 41 out of 3105\n",
      "handled 42 out of 3105\n",
      "handled 43 out of 3105\n",
      "handled 44 out of 3105\n",
      "handled 45 out of 3105\n",
      "handled 46 out of 3105\n",
      "handled 47 out of 3105\n",
      "handled 48 out of 3105\n",
      "handled 49 out of 3105\n",
      "handled 50 out of 3105\n",
      "handled 51 out of 3105\n",
      "handled 52 out of 3105\n",
      "handled 53 out of 3105\n",
      "handled 54 out of 3105\n",
      "handled 55 out of 3105\n",
      "handled 56 out of 3105\n",
      "handled 57 out of 3105\n",
      "handled 58 out of 3105\n",
      "handled 59 out of 3105\n",
      "handled 60 out of 3105\n",
      "handled 61 out of 3105\n",
      "handled 62 out of 3105\n",
      "handled 63 out of 3105\n",
      "handled 64 out of 3105\n",
      "handled 65 out of 3105\n",
      "handled 66 out of 3105\n",
      "handled 67 out of 3105\n",
      "handled 68 out of 3105\n",
      "handled 69 out of 3105\n",
      "handled 70 out of 3105\n",
      "handled 71 out of 3105\n",
      "handled 72 out of 3105\n",
      "handled 73 out of 3105\n",
      "handled 74 out of 3105\n",
      "handled 75 out of 3105\n",
      "handled 76 out of 3105\n",
      "handled 77 out of 3105\n",
      "handled 78 out of 3105\n",
      "handled 79 out of 3105\n",
      "handled 80 out of 3105\n",
      "handled 81 out of 3105\n",
      "handled 82 out of 3105\n",
      "handled 83 out of 3105\n",
      "handled 84 out of 3105\n",
      "handled 85 out of 3105\n",
      "handled 86 out of 3105\n",
      "handled 87 out of 3105\n",
      "handled 88 out of 3105\n",
      "handled 89 out of 3105\n",
      "handled 90 out of 3105\n",
      "handled 91 out of 3105\n",
      "handled 92 out of 3105\n",
      "handled 93 out of 3105\n",
      "handled 94 out of 3105\n",
      "handled 95 out of 3105\n",
      "handled 96 out of 3105\n",
      "handled 97 out of 3105\n",
      "handled 98 out of 3105\n",
      "handled 99 out of 3105\n",
      "handled 100 out of 3105\n",
      "handled 101 out of 3105\n",
      "handled 102 out of 3105\n",
      "handled 103 out of 3105\n",
      "handled 104 out of 3105\n",
      "handled 105 out of 3105\n",
      "handled 106 out of 3105\n",
      "handled 107 out of 3105\n",
      "handled 108 out of 3105\n",
      "handled 109 out of 3105\n",
      "handled 110 out of 3105\n",
      "handled 111 out of 3105\n",
      "handled 112 out of 3105\n",
      "handled 113 out of 3105\n",
      "handled 114 out of 3105\n",
      "handled 115 out of 3105\n",
      "handled 116 out of 3105\n",
      "handled 117 out of 3105\n",
      "handled 118 out of 3105\n",
      "handled 119 out of 3105\n",
      "handled 120 out of 3105\n",
      "handled 121 out of 3105\n",
      "handled 122 out of 3105\n",
      "handled 123 out of 3105\n",
      "handled 124 out of 3105\n",
      "handled 125 out of 3105\n",
      "handled 126 out of 3105\n",
      "handled 127 out of 3105\n",
      "handled 128 out of 3105\n",
      "handled 129 out of 3105\n",
      "handled 130 out of 3105\n",
      "handled 131 out of 3105\n",
      "handled 132 out of 3105\n",
      "handled 133 out of 3105\n",
      "handled 134 out of 3105\n",
      "handled 135 out of 3105\n",
      "handled 136 out of 3105\n",
      "handled 137 out of 3105\n",
      "handled 138 out of 3105\n",
      "handled 139 out of 3105\n",
      "handled 140 out of 3105\n",
      "handled 141 out of 3105\n",
      "handled 142 out of 3105\n",
      "handled 143 out of 3105\n",
      "handled 144 out of 3105\n",
      "handled 145 out of 3105\n",
      "handled 146 out of 3105\n",
      "handled 147 out of 3105\n",
      "handled 148 out of 3105\n",
      "handled 149 out of 3105\n",
      "handled 150 out of 3105\n",
      "handled 151 out of 3105\n",
      "handled 152 out of 3105\n",
      "handled 153 out of 3105\n",
      "handled 154 out of 3105\n",
      "handled 155 out of 3105\n",
      "handled 156 out of 3105\n",
      "handled 157 out of 3105\n",
      "handled 158 out of 3105\n",
      "handled 159 out of 3105\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "Settings = json.load(open('settings.txt'))\n",
    "from cabbage.features.ReId import StoredReId\n",
    "pprint(Settings)\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cabbage.regression.Regression import ReadOnlyRegression \n",
    "from cabbage.MultiplePeopleTracking import GraphGenerator\n",
    "from prototyping.experiments import MOT16_Experiments\n",
    "from os import makedirs, listdir\n",
    "from os.path import join, isfile, isdir, exists, splitext\n",
    "from time import time\n",
    "root = Settings['data_root']\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-02'\n",
    "video = mot16.mot16_02_X\n",
    "dmax = 5\n",
    "\n",
    "#Dt = mot16.mot16_02_detections\n",
    "Dt = mot16.mot16_02_true_detections_no_pid\n",
    "\n",
    "reid = StoredReId(root, 5)\n",
    "\n",
    "# TODO load automaticaly\n",
    "pred_model = join(reid.root, 'predict_MOT16-02_dmax100.npy')\n",
    "brok_model = join(reid.root, 'broken_MOT16-02_dmax100.npy')\n",
    "\n",
    "reid.load_memory(pred_model, brok_model)\n",
    "\n",
    "print(\"Dt\", Dt.shape)\n",
    "\n",
    "o = 300\n",
    "a = Dt[0]\n",
    "b = Dt[o]\n",
    "frame1, frame2 = a[0], b[0]\n",
    "delta = int(abs(frame2-frame1) )\n",
    "\n",
    "print(a, b)\n",
    "print(delta)\n",
    "print('prediction', reid.predict(0, o))\n",
    "\n",
    "reid.memorize(Dt, video, 'DM_' + video_name + '_dmax100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/home/stasysp/Envs/Datasets/MOT16/',\n",
      " 'deepmatch': '/home/stasysp/Envs/shad/project/cabbage/deepmatching_bin/deepmatching_1.2.2_c++/deepmatching-static',\n",
      " 'graph_solver': '/home/stasysp/Envs/shad/project/cabbage/build/sample'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Found model /home/stasysp/Envs/Datasets/MOT16/reid_models/stacknet64x64_84acc.h5! :)\n",
      "WARNING:tensorflow:From /home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "Dt (252, 6)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create lookup structure, elapsed: 0.4056732654571533\n",
      "ALL PAIRS: (27550, 2)\n",
      "\telapsed seconds: 0.00554966926574707\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Frame 1 not in /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c6d7eb34e20c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGraphGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, Dt, X, W, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             delta, edge_weights, i_, j_ = gen_feature_batch(\n\u001b[0;32m--> 120\u001b[0;31m                 batch, lookup, dmax, dm, reid, W, video_name)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36mgen_feature_batch\u001b[0;34m(batch, lookup, dmax, dm, reid, W, video_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mcalculate_cost\u001b[0;34m(self, video_name, frame1, bb1, frame2, bb2)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbb2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0maabb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mis_same_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_match\u001b[0;34m(self, video_name, frame1, frame2)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"First frame must be greater/equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_matches\u001b[0;34m(self, video_name, frame_nbr)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Data location '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' does not exist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_nbr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' not in '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Frame 1 not in /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "Settings = json.load(open('settings.txt'))\n",
    "pprint(Settings)\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cabbage.regression.Regression import get_W_mot16_02_dmax100\n",
    "from cabbage.MultiplePeopleTracking import GraphGenerator, BatchGraphGenerator, AABBLookup\n",
    "from cabbage.features.deepmatching import ReadOnlyDeepMatching\n",
    "from cabbage.features.ReId import StoredReId, StackNet64x64, get_element\n",
    "from prototyping.experiments import MOT16_Experiments\n",
    "from cabbage.data.video import VideoData\n",
    "from time import time\n",
    "root = Settings['data_root']\n",
    "print(\"\\n\")\n",
    "\n",
    "reid = StackNet64x64(root)\n",
    "dm = ReadOnlyDeepMatching(root, 100)  # deep matches are set-up for 100 frames\n",
    "\n",
    "dmax = 30\n",
    "\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-02'\n",
    "X = mot16.mot16_11_X\n",
    "\n",
    "#Dt = mot16.mot16_11_detections\n",
    "Dt = mot16.mot16_02_true_detections_no_pid\n",
    "vd = VideoData(Dt)\n",
    "Dt = vd.get_n_first_frames(50)\n",
    "\n",
    "W = get_W_mot16_02_dmax100(root)\n",
    "\n",
    "print(\"\\nDt\", Dt.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "generator = BatchGraphGenerator(root, reid=reid, dm=dm, dmax=dmax, video_name=video_name)\n",
    "generator.build(Dt, X, W, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100', [], [])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for i in os.walk('/home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DM_MOT16-02_dmax100'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'DM_' + video_name + '_dmax100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from cabbage.MultiplePeopleTracking import execute_multiple_people_tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/home/stasysp/Envs/Datasets/MOT16/',\n",
      " 'deepmatch': '/home/stasysp/Envs/shad/project/cabbage/deepmatching_bin/deepmatching_1.2.2_c++/deepmatching-static',\n",
      " 'graph_solver': '/home/stasysp/Envs/shad/project/cabbage/build/sample'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "Settings = json.load(open('settings.txt'))\n",
    "pprint(Settings)\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cabbage.regression.Regression import get_W_mot16_02_dmax100\n",
    "from cabbage.MultiplePeopleTracking import GraphGenerator, BatchGraphGenerator, AABBLookup\n",
    "from cabbage.features.deepmatching import ReadOnlyDeepMatching\n",
    "from cabbage.features.ReId import StoredReId, StackNet64x64, get_element\n",
    "from prototyping.experiments import MOT16_Experiments\n",
    "from cabbage.data.video import VideoData\n",
    "from time import time\n",
    "root = Settings['data_root']\n",
    "print(\"\\n\")\n",
    "\n",
    "reid = StackNet64x64(root)\n",
    "dm = ReadOnlyDeepMatching(root, 100)  # deep matches are set-up for 100 frames\n",
    "\n",
    "dmax = 30\n",
    "\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-11'\n",
    "X = mot16.mot16_11_X\n",
    "\n",
    "#Dt = mot16.mot16_11_detections\n",
    "Dt = mot16.mot16_11_true_detections_no_pid\n",
    "vd = VideoData(Dt)\n",
    "Dt = vd.get_n_first_frames(50)\n",
    "\n",
    "W = get_W_mot16_02_dmax100(root)\n",
    "\n",
    "print(\"\\nDt\", Dt.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "generator = BatchGraphGenerator(root, reid=reid, dm=dm, dmax=dmax, video_name=video_name)\n",
    "generator.build(Dt, X, W, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model /home/stasysp/Envs/Datasets/MOT16/reid_models/stacknet64x64_84acc.h5! :)\n",
      "\n",
      "Dt (267, 6)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create lookup structure, elapsed: 0.5382108688354492\n",
      "ALL PAIRS: (30793, 2)\n",
      "\telapsed seconds: 0.0068187713623046875\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Data location /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-11_dmax100 does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-d4e3fdf2ef03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGraphGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, Dt, X, W, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             delta, edge_weights, i_, j_ = gen_feature_batch(\n\u001b[0;32m--> 120\u001b[0;31m                 batch, lookup, dmax, dm, reid, W, video_name)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36mgen_feature_batch\u001b[0;34m(batch, lookup, dmax, dm, reid, W, video_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mcalculate_cost\u001b[0;34m(self, video_name, frame1, bb1, frame2, bb2)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbb2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0maabb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mis_same_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_match\u001b[0;34m(self, video_name, frame1, frame2)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"First frame must be greater/equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_matches\u001b[0;34m(self, video_name, frame_nbr)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mfolder_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_video_folder_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_file_name_for_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_nbr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Data location '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' does not exist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_nbr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' not in '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Data location /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-11_dmax100 does not exist"
     ]
    }
   ],
   "source": [
    "reid = StackNet64x64(root)\n",
    "dm = ReadOnlyDeepMatching(root, 100)  # deep matches are set-up for 100 frames\n",
    "\n",
    "dmax = 30\n",
    "\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-11'\n",
    "X = mot16.mot16_11_X\n",
    "\n",
    "#Dt = mot16.mot16_11_detections\n",
    "Dt = mot16.mot16_11_true_detections_no_pid\n",
    "vd = VideoData(Dt)\n",
    "Dt = vd.get_n_first_frames(50)\n",
    "\n",
    "W = get_W_mot16_02_dmax100(root)\n",
    "\n",
    "print(\"\\nDt\", Dt.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "generator = BatchGraphGenerator(root, reid=reid, dm=dm, dmax=dmax, video_name=video_name)\n",
    "generator.build(Dt, X, W, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-02'\n",
    "X = mot16.mot16_02_X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dt (252, 6)\n"
     ]
    }
   ],
   "source": [
    "Dt = mot16.mot16_02_true_detections_no_pid\n",
    "vd = VideoData(Dt)\n",
    "Dt = vd.get_n_first_frames(50)\n",
    "\n",
    "W = get_W_mot16_02_dmax100(root)\n",
    "\n",
    "print(\"Dt\", Dt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{DM}: solve 1 -> 1\n",
      "{DM}: solve 1 -> 2\n",
      "{DM}: solve 1 -> 3\n",
      "{DM}: solve 1 -> 4\n",
      "{DM}: solve 1 -> 5\n",
      "{DM}: solve 1 -> 6\n",
      "{DM}: solve 1 -> 7\n",
      "{DM}: solve 1 -> 8\n",
      "{DM}: solve 1 -> 9\n",
      "{DM}: solve 1 -> 10\n",
      "{DM}: solve 1 -> 11\n",
      "{DM}: solve 1 -> 12\n",
      "{DM}: solve 1 -> 13\n",
      "{DM}: solve 1 -> 14\n",
      "{DM}: solve 1 -> 15\n",
      "{DM}: solve 1 -> 16\n",
      "{DM}: solve 1 -> 17\n",
      "{DM}: solve 1 -> 18\n",
      "{DM}: solve 1 -> 19\n",
      "{DM}: solve 1 -> 20\n",
      "{DM}: solve 1 -> 21\n",
      "{DM}: solve 1 -> 22\n",
      "{DM}: solve 1 -> 23\n",
      "{DM}: solve 1 -> 24\n",
      "{DM}: solve 1 -> 25\n",
      "{DM}: solve 1 -> 26\n",
      "{DM}: solve 1 -> 27\n",
      "{DM}: solve 1 -> 28\n",
      "{DM}: solve 1 -> 29\n",
      "{DM}: solve 1 -> 30\n",
      "{DM}: solve 1 -> 31\n",
      "{DM}: solve 1 -> 32\n",
      "{DM}: solve 1 -> 33\n",
      "{DM}: solve 1 -> 34\n",
      "{DM}: solve 1 -> 35\n",
      "{DM}: solve 1 -> 36\n",
      "{DM}: solve 1 -> 37\n",
      "{DM}: solve 1 -> 38\n",
      "{DM}: solve 1 -> 39\n",
      "{DM}: solve 1 -> 40\n",
      "{DM}: solve 1 -> 41\n",
      "{DM}: solve 1 -> 42\n",
      "{DM}: solve 1 -> 43\n",
      "{DM}: solve 1 -> 44\n",
      "{DM}: solve 1 -> 45\n",
      "{DM}: solve 1 -> 46\n",
      "{DM}: solve 1 -> 47\n",
      "{DM}: solve 1 -> 48\n",
      "{DM}: solve 1 -> 49\n",
      "{DM}: solve 1 -> 50\n",
      "{DM}: solve 1 -> 51\n",
      "{DM}: solve 1 -> 52\n",
      "{DM}: solve 1 -> 53\n",
      "{DM}: solve 1 -> 54\n",
      "{DM}: solve 1 -> 55\n",
      "{DM}: solve 1 -> 56\n",
      "{DM}: solve 1 -> 57\n",
      "{DM}: solve 1 -> 58\n",
      "{DM}: solve 1 -> 59\n",
      "{DM}: solve 1 -> 60\n",
      "{DM}: solve 1 -> 61\n",
      "{DM}: solve 1 -> 62\n",
      "{DM}: solve 1 -> 63\n",
      "{DM}: solve 1 -> 64\n",
      "{DM}: solve 1 -> 65\n",
      "{DM}: solve 1 -> 66\n",
      "{DM}: solve 1 -> 67\n",
      "{DM}: solve 1 -> 68\n",
      "{DM}: solve 1 -> 69\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2e11ea0e814d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msettings_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./settings.txt'\u001b[0m  \u001b[0;31m# generated by the install.sh script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mexecute_multiple_people_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mexecute_multiple_people_tracking\u001b[0;34m(video_folder, X, Dt, video_name, dmax, settings_file, batch_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mdm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepMatching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeep_matching_binary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mreid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackNet64x64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mgenerate_matches\u001b[0;34m(self, video_folder, video_name, img_type, verbose, force_overwrite)\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{DM}: solve \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" -> \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                 \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0mcurr_frame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mdeepmatch\u001b[0;34m(self, img1, img2)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepmatch_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-downscale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-nt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mpopen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mpopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout, endtime)\u001b[0m\n\u001b[1;32m   1656\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1659\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1606\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1608\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1609\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time \n",
    "video_name = 'MOT16-02'\n",
    "n, h, w = 15, 1080, 1920\n",
    "\n",
    "dmax = 100\n",
    "\n",
    "video_loc = '/home/stasysp/Envs/Datasets/MOT16/MOT16/train/MOT16-02/img1'  # the video must be stored as a folder with the individual frames\n",
    "\n",
    "settings_loc = './settings.txt'  # generated by the install.sh script\n",
    "\n",
    "execute_multiple_people_tracking(video_loc, X, Dt, video_name, dmax, settings_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create lookup structure, elapsed: 0.4152395725250244\n",
      "ALL PAIRS: (27550, 2)\n",
      "\telapsed seconds: 0.005933284759521484\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Frame 1 not in /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6c6bd894fd16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGraphGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, Dt, X, W, batch_size)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             delta, edge_weights, i_, j_ = gen_feature_batch(\n\u001b[0;32m--> 120\u001b[0;31m                 batch, lookup, dmax, dm, reid, W, video_name)\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36mgen_feature_batch\u001b[0;34m(batch, lookup, dmax, dm, reid, W, video_name)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    123\u001b[0m     DM = np.array(\n\u001b[1;32m    124\u001b[0m         [dm.calculate_cost(video_name, f1, bb1, f2, bb2) for \\\n\u001b[0;32m--> 125\u001b[0;31m             f1, bb1, f2, bb2 in zip(frame_i, aabb_i, frame_j, aabb_j)]\n\u001b[0m\u001b[1;32m    126\u001b[0m     )\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mcalculate_cost\u001b[0;34m(self, video_name, frame1, bb1, frame2, bb2)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mbb2\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0maabb\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \"\"\"\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mis_same_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_match\u001b[0;34m(self, video_name, frame1, frame2)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mframe1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mframe1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"First frame must be greater/equal\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mframe1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/deepmatching.py\u001b[0m in \u001b[0;36mget_matches\u001b[0;34m(self, video_name, frame_nbr)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Data location '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' does not exist'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Frame '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_nbr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' not in '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Frame 1 not in /home/stasysp/Envs/Datasets/MOT16/DM_MOT16-02_dmax100"
     ]
    }
   ],
   "source": [
    "generator = BatchGraphGenerator(root, reid=reid, dm=dm, dmax=dmax, video_name=video_name)\n",
    "generator.build(Dt, X, W, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cabbage.data import MOT16Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "frame = cv2.imread('/home/stasysp/Envs/Datasets/MOT16/train/MOT16-02/img1/000001.jpg')\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "for i in os.walk('/home/stasysp/Envs/Datasets/MOT16/train/MOT16-02/img1'):\n",
    "    print(len(sorted(i[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found model /tmp/mpt/reid_models/stacknet64x64_84acc.h5! :)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stasysp/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-18448f544f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0msettings_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./settings.txt'\u001b[0m  \u001b[0;31m# generated by the install.sh script\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mexecute_multiple_people_tracking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_loc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_loc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mexecute_multiple_people_tracking\u001b[0;34m(video_folder, X, Dt, video_name, dmax, settings_file, batch_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGraphGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0medge_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlifted_edge_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'output.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/MultiplePeopleTracking.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, Dt, X, W, batch_size)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0m__start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mlookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAABBLookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0m__end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'create lookup structure, elapsed:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m__start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/combined.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, Dt, X, H, W)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAABBs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/project/cabbage/cabbage/features/ReId.py\u001b[0m in \u001b[0;36mget_element\u001b[0;34m(X, bb, shape, force_uint, preprocess)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforce_uint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'constant'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1.01\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(image, output_shape, order, mode, cval, clip, preserve_range, anti_aliasing, anti_aliasing_sigma)\u001b[0m\n\u001b[1;32m    167\u001b[0m         out = warp(image, tform, output_shape=output_shape, order=order,\n\u001b[1;32m    168\u001b[0m                    \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m                    preserve_range=preserve_range)\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# n-dimensional interpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36mwarp\u001b[0;34m(image, inverse_map, map_args, output_shape, order, mode, cval, clip, preserve_range)\u001b[0m\n\u001b[1;32m    894\u001b[0m                                      mode=ndi_mode, order=order, cval=cval)\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m     \u001b[0m_clip_warp_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwarped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/shad_venv/lib/python3.5/site-packages/skimage/transform/_warps.py\u001b[0m in \u001b[0;36m_clip_warp_output\u001b[0;34m(input_image, output_image, order, mode, cval, clip)\u001b[0m\n\u001b[1;32m    646\u001b[0m     \"\"\"\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclip\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mmin_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0mmax_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Envs/shad/shad_venv/lib/python3.5/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims, initial)\u001b[0m\n\u001b[1;32m     30\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     31\u001b[0m           initial=_NoValue):\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "import time \n",
    "video_name = 'MOT16-02'\n",
    "n, h, w = 15, 1080, 1920\n",
    "X = np.zeros((n, h, w, 3))  # the whole video loaded as np array\n",
    "\n",
    "frames = []\n",
    "for i in os.walk('/home/stasysp/Envs/Datasets/MOT16/MOT16/train/MOT16-02/img1'):\n",
    "    frames = sorted(i[2])\n",
    "for i, j in enumerate(frames):\n",
    "    X[i] = cv2.imread('/home/stasysp/Envs/Datasets/MOT16/MOT16/MOT16/train/MOT16-02/img1/' + j)\n",
    "\n",
    "dmax = 5\n",
    "\n",
    "m = 15\n",
    "Dt = np.zeros((m, 6))  # m=number of detections\n",
    "\n",
    "video_loc = '/home/stasysp/Envs/Datasets/MOT16/MOT16/train/MOT16-02/img1'  # the video must be stored as a folder with the individual frames\n",
    "\n",
    "settings_loc = './settings.txt'  # generated by the install.sh script\n",
    "\n",
    "execute_multiple_people_tracking(video_loc, X, Dt, video_name, dmax, settings_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_root': '/tmp/mpt',\n",
      " 'deepmatch': '/home/stasysp/Envs/shad/project/cabbage/deepmatching_bin/deepmatching_1.2.2_c++/deepmatching-static',\n",
      " 'graph_solver': '/home/stasysp/Envs/shad/project/cabbage/build/sample'}\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'experiments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-739f3ca3d568>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcabbage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultiplePeopleTracking\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexecute_multiple_people_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mexperiments\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMOT16_Experiments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcabbage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVideoData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'experiments'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "Settings = json.load(open('settings.txt'))\n",
    "pprint(Settings)\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from cabbage.MultiplePeopleTracking import execute_multiple_people_tracking\n",
    "from experiments import MOT16_Experiments\n",
    "from cabbage.data.video import VideoData\n",
    "\n",
    "root = Settings['data_root']\n",
    "\n",
    "mot16 = MOT16_Experiments(root)\n",
    "video_name = 'MOT16-02'\n",
    "X = mot16.mot16_11_X\n",
    "dmax = 5\n",
    "\n",
    "Dt = mot16.mot16_11_detections\n",
    "\n",
    "video_loc ='/home/stasysp/Envs/Datasets/MOT16/train/MOT16-02/img1'\n",
    "\n",
    "execute_multiple_people_tracking(video_loc, X, Dt, video_name, dmax, 'settings.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
